#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥æ¨¡å‹ç‰¹å¾ç»´åº¦çš„è„šæœ¬
"""

import torch
from PromptAD import PromptAD

def check_model_dimensions():
    """æ£€æŸ¥æ¨¡å‹çš„å®é™…ç‰¹å¾ç»´åº¦"""
    # è®¾ç½®åŸºæœ¬å‚æ•°
    args = {
        'dataset': 'mvtec',
        'class_name': 'carpet',
        'img_resize': 240,
        'img_cropsize': 240,
        'resolution': 400,
        'batch_size': 4,
        'k_shot': 1,
        'backbone': 'ViT-B-16-plus-240',
        'pretrained_dataset': 'laion400m_e32',
        'n_ctx': 4,
        'n_ctx_ab': 1,
        'n_pro': 1,
        'n_pro_ab': 4,
        'enable_fusion': False,  # å…ˆç¦ç”¨èåˆ
        'device': 'cuda:0' if torch.cuda.is_available() else 'cpu',
        'out_size_h': 400,
        'out_size_w': 400,
        'load_memory': False,
        'version': ''
    }
    
    print(f"ä½¿ç”¨è®¾å¤‡: {args['device']}")
    
    try:
        # åˆ›å»ºæ¨¡å‹
        print("æ­£åœ¨åˆ›å»ºPromptADæ¨¡å‹...")
        model = PromptAD(**args)
        model = model.to(args['device'])
        
        # æ£€æŸ¥æ¨¡å‹å±æ€§
        print("\n=== æ¨¡å‹ç»´åº¦ä¿¡æ¯ ===")
        if hasattr(model.model, 'visual'):
            visual = model.model.visual
            print(f"visual.embed_dim: {getattr(visual, 'embed_dim', 'N/A')}")
            print(f"visual.width: {getattr(visual, 'width', 'N/A')}")
            print(f"visual.output_dim: {getattr(visual, 'output_dim', 'N/A')}")
            
        if hasattr(model.model, 'text_projection'):
            print(f"text_projection.shape: {model.model.text_projection.shape}")
            
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        print("\n=== æµ‹è¯•ç‰¹å¾ç»´åº¦ ===")
        batch_size = 2
        images = torch.randn(batch_size, 3, 240, 240).to(args['device'])
        
        # æµ‹è¯•å›¾åƒç¼–ç 
        with torch.no_grad():
            features = model.encode_image(images)
            print(f"encode_imageè¿”å›ç‰¹å¾æ•°é‡: {len(features)}")
            for i, feat in enumerate(features):
                if feat is not None:
                    print(f"  ç‰¹å¾ {i}: {feat.shape}")
                else:
                    print(f"  ç‰¹å¾ {i}: None")
        
        # æµ‹è¯•æ–‡æœ¬ç¼–ç 
        print("\n=== æµ‹è¯•æ–‡æœ¬ç‰¹å¾ ===")
        normal_text_embeddings, abnormal_text_embeddings_handle, abnormal_text_embeddings_learned = model.prompt_learner()
        print(f"normal_text_embeddings: {normal_text_embeddings.shape}")
        print(f"abnormal_text_embeddings_handle: {abnormal_text_embeddings_handle.shape}")
        print(f"abnormal_text_embeddings_learned: {abnormal_text_embeddings_learned.shape}")
        
        # ç¼–ç æ–‡æœ¬ç‰¹å¾
        normal_text_features = model.encode_text_embedding(normal_text_embeddings, model.tokenized_normal_prompts)
        print(f"normal_text_features: {normal_text_features.shape}")
        
        print("\nâœ… ç»´åº¦æ£€æŸ¥å®Œæˆï¼")
        
    except Exception as e:
        print(f"âŒ æ£€æŸ¥è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == '__main__':
    print("å¼€å§‹æ£€æŸ¥æ¨¡å‹ç»´åº¦...")
    success = check_model_dimensions()
    if success:
        print("\nğŸ‰ ç»´åº¦æ£€æŸ¥å®Œæˆï¼")
    else:
        print("\nğŸ’¥ ç»´åº¦æ£€æŸ¥å¤±è´¥ã€‚")