#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•è§†è§‰-æ–‡æœ¬èåˆåŠŸèƒ½çš„ç®€å•è„šæœ¬
"""

import torch
import argparse
from PromptAD import PromptAD
from datasets import get_dataloader_from_args

def test_fusion():
    """æµ‹è¯•èåˆåŠŸèƒ½"""
    # è®¾ç½®åŸºæœ¬å‚æ•°
    args = {
        'dataset': 'mvtec',
        'class_name': 'carpet',
        'img_resize': 240,
        'img_cropsize': 240,
        'resolution': 400,
        'batch_size': 4,
        'k_shot': 1,
        'backbone': 'ViT-B-16-plus-240',
        'pretrained_dataset': 'laion400m_e32',
        'n_ctx': 4,
        'n_ctx_ab': 1,
        'n_pro': 1,
        'n_pro_ab': 4,
        'enable_fusion': True,  # å¯ç”¨èåˆ
        'device': 'cuda:0' if torch.cuda.is_available() else 'cpu',
        'out_size_h': 400,
        'out_size_w': 400,
        'load_memory': False,
        'version': ''
    }
    
    print(f"ä½¿ç”¨è®¾å¤‡: {args['device']}")
    
    try:
        # åˆ›å»ºæ¨¡å‹
        print("æ­£åœ¨åˆ›å»ºPromptADæ¨¡å‹...")
        model = PromptAD(**args)
        model = model.to(args['device'])
        print(f"æ¨¡å‹åˆ›å»ºæˆåŠŸï¼ŒèåˆåŠŸèƒ½å·²{'å¯ç”¨' if model.enable_fusion else 'ç¦ç”¨'}")
        
        # åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®ï¼ˆé¿å…ä¾èµ–å®é™…æ•°æ®é›†æ–‡ä»¶ï¼‰
        print("æ­£åœ¨åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®...")
        batch_size = 2
        # åˆ›å»ºéšæœºå›¾åƒæ•°æ® (B, C, H, W)
        images = torch.randn(batch_size, 3, 240, 240).to(args['device'])
        print(f"æ¨¡æ‹Ÿå›¾åƒå½¢çŠ¶: {images.shape}")
        
        # æµ‹è¯•åŸå§‹å›¾åƒç¼–ç 
        print("\næµ‹è¯•åŸå§‹å›¾åƒç¼–ç ...")
        with torch.no_grad():
            original_features = model.encode_image(images)
            if isinstance(original_features, list):
                print(f"åŸå§‹ç‰¹å¾: åŒ…å« {len(original_features)} ä¸ªç‰¹å¾å±‚")
                for i, feat in enumerate(original_features):
                    print(f"  å±‚ {i}: {feat.shape}")
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªç‰¹å¾è¿›è¡Œåç»­æµ‹è¯•
                original_main_feature = original_features[0]
            else:
                print(f"åŸå§‹ç‰¹å¾å½¢çŠ¶: {original_features.shape}")
                original_main_feature = original_features
        
        # æµ‹è¯•èåˆç‰¹å¾ç¼–ç 
        if model.enable_fusion:
            print("\næµ‹è¯•èåˆç‰¹å¾ç¼–ç ...")
            with torch.no_grad():
                fused_features = model.encode_fused_features(images)
                if isinstance(fused_features, list):
                    print(f"èåˆç‰¹å¾: åŒ…å« {len(fused_features)} ä¸ªç‰¹å¾å±‚")
                    for i, feat in enumerate(fused_features):
                        print(f"  å±‚ {i}: {feat.shape}")
                    # ä½¿ç”¨ç¬¬ä¸€ä¸ªç‰¹å¾è¿›è¡Œæ¯”è¾ƒ
                    fused_main_feature = fused_features[0]
                else:
                    print(f"èåˆç‰¹å¾å½¢çŠ¶: {fused_features.shape}")
                    fused_main_feature = fused_features
                
                # è®¡ç®—ç‰¹å¾å·®å¼‚
                if original_main_feature.shape == fused_main_feature.shape:
                    feature_diff = torch.mean(torch.abs(fused_main_feature - original_main_feature))
                    print(f"èåˆç‰¹å¾ä¸åŸå§‹ç‰¹å¾çš„å¹³å‡ç»å¯¹å·®å¼‚: {feature_diff.item():.6f}")
                else:
                    print(f"ç‰¹å¾å½¢çŠ¶ä¸åŒ¹é…ï¼Œæ— æ³•è®¡ç®—å·®å¼‚: {original_main_feature.shape} vs {fused_main_feature.shape}")
        
        # æµ‹è¯•å®Œæ•´çš„å‰å‘ä¼ æ’­
        print("\næµ‹è¯•å®Œæ•´å‰å‘ä¼ æ’­...")
        model.eval()
        with torch.no_grad():
            # æµ‹è¯•åˆ†ç±»ä»»åŠ¡
            result_cls = model(images, task='classification', use_fusion=True)
            if result_cls is not None:
                if isinstance(result_cls, (list, tuple)):
                    print(f"åˆ†ç±»ç»“æœ: {len(result_cls)} ä¸ªè¾“å‡º")
                else:
                    print(f"åˆ†ç±»ç»“æœå½¢çŠ¶: {result_cls.shape}")
            else:
                print("åˆ†ç±»ç»“æœ: None (å¯èƒ½éœ€è¦å…ˆæ„å»ºæ–‡æœ¬ç‰¹å¾åº“)")
            
            # æµ‹è¯•åˆ†å‰²ä»»åŠ¡
            result_seg = model(images, task='segmentation', use_fusion=True)
            if result_seg is not None:
                print(f"åˆ†å‰²ç»“æœå½¢çŠ¶: {result_seg.shape}")
            else:
                print("åˆ†å‰²ç»“æœ: None (å¯èƒ½éœ€è¦å…ˆæ„å»ºæ–‡æœ¬ç‰¹å¾åº“)")
        
        print("\nâœ… èåˆåŠŸèƒ½æµ‹è¯•æˆåŠŸï¼")
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == '__main__':
    print("å¼€å§‹æµ‹è¯•è§†è§‰-æ–‡æœ¬èåˆåŠŸèƒ½...")
    success = test_fusion()
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼èåˆåŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
    else:
        print("\nğŸ’¥ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ã€‚")