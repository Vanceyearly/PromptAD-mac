#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸“é—¨æµ‹è¯•tokenç‰¹å¾èåˆçš„è„šæœ¬
"""

import torch
from PromptAD import PromptAD

def test_token_fusion():
    """æµ‹è¯•tokenç‰¹å¾èåˆ"""
    # è®¾ç½®åŸºæœ¬å‚æ•°
    args = {
        'dataset': 'mvtec',
        'class_name': 'carpet',
        'img_resize': 240,
        'img_cropsize': 240,
        'resolution': 400,
        'batch_size': 4,
        'k_shot': 1,
        'backbone': 'ViT-B-16-plus-240',
        'pretrained_dataset': 'laion400m_e32',
        'n_ctx': 4,
        'n_ctx_ab': 1,
        'n_pro': 1,
        'n_pro_ab': 4,
        'enable_fusion': True,
        'device': 'cpu',  # ä½¿ç”¨CPUé¿å…CUDAé—®é¢˜
        'out_size_h': 400,
        'out_size_w': 400,
        'load_memory': False,
        'version': ''
    }
    
    print(f"ä½¿ç”¨è®¾å¤‡: {args['device']}")
    
    try:
        # åˆ›å»ºæ¨¡å‹
        print("æ­£åœ¨åˆ›å»ºPromptADæ¨¡å‹...")
        model = PromptAD(**args)
        model = model.to(args['device'])
        model.eval()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        batch_size = 2
        images = torch.randn(batch_size, 3, 240, 240).to(args['device'])
        
        # å¦‚æœæ¨¡å‹ä½¿ç”¨fp16ï¼Œè½¬æ¢è¾“å…¥
        if hasattr(model.model.visual, 'conv1') and model.model.visual.conv1.weight.dtype == torch.float16:
            images = images.half()
        
        print(f"æµ‹è¯•å›¾åƒå½¢çŠ¶: {images.shape}, dtype: {images.dtype}")
        
        # è·å–åŸå§‹è§†è§‰ç‰¹å¾
        print("\n=== è·å–åŸå§‹è§†è§‰ç‰¹å¾ ===")
        with torch.no_grad():
            visual_features = model.encode_image(images)
            for i, feat in enumerate(visual_features):
                print(f"è§†è§‰ç‰¹å¾ {i}: {feat.shape}")
        
        # è·å–æ–‡æœ¬ç‰¹å¾
        print("\n=== è·å–æ–‡æœ¬ç‰¹å¾ ===")
        with torch.no_grad():
            normal_text_embeddings, abnormal_text_embeddings_handle, abnormal_text_embeddings_learned = model.prompt_learner()
            abnormal_text_embeddings = torch.cat([abnormal_text_embeddings_handle, abnormal_text_embeddings_learned], dim=0)
            
            print(f"normal_text_embeddings: {normal_text_embeddings.shape}")
            print(f"abnormal_text_embeddings_handle: {abnormal_text_embeddings_handle.shape}")
            print(f"abnormal_text_embeddings_learned: {abnormal_text_embeddings_learned.shape}")
            
            # ä½¿ç”¨æ­£ç¡®çš„tokenized prompts
            normal_text_features = model.encode_text_embedding(normal_text_embeddings, model.tokenized_normal_prompts)
            
            # ä¸ºabnormalç‰¹å¾ä½¿ç”¨æ­£ç¡®çš„tokenæ•°é‡
            tokenized_abnormal_handle = model.tokenized_abnormal_prompts[:abnormal_text_embeddings_handle.shape[0]]
            tokenized_abnormal_learned = model.tokenized_abnormal_prompts[:abnormal_text_embeddings_learned.shape[0]]
            
            abnormal_text_features_handle = model.encode_text_embedding(abnormal_text_embeddings_handle, tokenized_abnormal_handle)
            abnormal_text_features_learned = model.encode_text_embedding(abnormal_text_embeddings_learned, tokenized_abnormal_learned)
            abnormal_text_features = torch.cat([abnormal_text_features_handle, abnormal_text_features_learned], dim=0)
            
            print(f"normal_text_features: {normal_text_features.shape}")
            print(f"abnormal_text_features_handle: {abnormal_text_features_handle.shape}")
            print(f"abnormal_text_features_learned: {abnormal_text_features_learned.shape}")
            print(f"åˆå¹¶åçš„abnormal_text_features: {abnormal_text_features.shape}")
        
        # æµ‹è¯•æ¯ä¸ªè§†è§‰ç‰¹å¾çš„èåˆ
        print("\n=== æµ‹è¯•å„ä¸ªç‰¹å¾çš„èåˆ ===")
        with torch.no_grad():
            for i, v_feat in enumerate(visual_features):
                print(f"\n--- æµ‹è¯•ç‰¹å¾ {i} ---")
                print(f"v_featå½¢çŠ¶: {v_feat.shape}")
                
                # é€‰æ‹©åˆé€‚çš„èåˆæ¨¡å—
                if v_feat.shape[-1] == 640:
                    cross_attention = model.cross_modal_attention_640
                    fusion_weight_net = model.fusion_weight_net_640
                    projection = model.fused_projection_640
                    print("ä½¿ç”¨640ç»´èåˆæ¨¡å—")
                elif v_feat.shape[-1] == 896:
                    cross_attention = model.cross_modal_attention_896
                    fusion_weight_net = model.fusion_weight_net_896
                    projection = model.fused_projection_896
                    print("ä½¿ç”¨896ç»´èåˆæ¨¡å—")
                else:
                    print(f"æœªçŸ¥ç‰¹å¾ç»´åº¦: {v_feat.shape[-1]}")
                    continue
                
                # å‡†å¤‡æ–‡æœ¬ç‰¹å¾
                text_feat = normal_text_features
                if len(text_feat.shape) == 2 and text_feat.shape[0] != v_feat.shape[0]:
                    text_feat = text_feat.expand(v_feat.shape[0], -1)
                
                print(f"text_featå½¢çŠ¶: {text_feat.shape}")
                
                try:
                    # è·¨æ¨¡æ€æ³¨æ„åŠ›
                    print("æ‰§è¡Œè·¨æ¨¡æ€æ³¨æ„åŠ›...")
                    v_input = v_feat.unsqueeze(1) if len(v_feat.shape) == 2 else v_feat
                    t_input = text_feat.unsqueeze(1) if len(text_feat.shape) == 2 else text_feat
                    
                    print(f"æ³¨æ„åŠ›è¾“å…¥ - v_input: {v_input.shape}, t_input: {t_input.shape}")
                    
                    v_fused, t_fused = cross_attention(v_input, t_input)
                    print(f"æ³¨æ„åŠ›è¾“å‡º - v_fused: {v_fused.shape}, t_fused: {t_fused.shape}")
                    
                    print(f"âœ… ç‰¹å¾ {i} èåˆæˆåŠŸ")
                    
                except Exception as e:
                    print(f"âŒ ç‰¹å¾ {i} èåˆå¤±è´¥: {str(e)}")
                    import traceback
                    traceback.print_exc()
                    return False
        
        print("\nâœ… æ‰€æœ‰tokenç‰¹å¾èåˆæµ‹è¯•æˆåŠŸï¼")
        return True
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == '__main__':
    print("å¼€å§‹æµ‹è¯•tokenç‰¹å¾èåˆåŠŸèƒ½...")
    success = test_token_fusion()
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nğŸ’¥ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ã€‚")